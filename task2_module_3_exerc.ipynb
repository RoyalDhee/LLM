{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba7dcfc",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b534d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9cc37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✅ Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Sample document\n",
    "sentences = [\n",
    "    \"The dog is playing in the park\",\n",
    "    \"A puppy is running outside\",\n",
    "    \"The cat is sleeping on the couch\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning models need data\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "\n",
    "# Load a small, fast embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✅ Model loaded!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74248d",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a872387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (6, 384)\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "First 10 values: [[ 0.04757566 -0.07015254  0.06429747 ...  0.07358795  0.01249521\n",
      "   0.01645607]\n",
      " [-0.0252566   0.03054357  0.05249949 ...  0.01063142  0.01476685\n",
      "   0.10832039]\n",
      " [ 0.1220389  -0.04751379 -0.00115911 ...  0.08472571  0.06573965\n",
      "   0.0092331 ]\n",
      " [-0.03537082  0.038165   -0.04126012 ...  0.11130317  0.19625439\n",
      "  -0.02897431]\n",
      " [ 0.01665926 -0.04558857  0.02346508 ...  0.02717928 -0.03379644\n",
      "  -0.05370044]\n",
      " [-0.06430853  0.0156419  -0.04678493 ...  0.15115134  0.10791415\n",
      "  -0.04270948]]\n"
     ]
    }
   ],
   "source": [
    "# Generate embedding\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# print(f\"Original text: {sentences}\")\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Embedding type: {type(embeddings)}\")\n",
    "print(f\"\\nFirst 10 values: {embeddings[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156aec3f",
   "metadata": {},
   "source": [
    "### Calculate Similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d25b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function ready!\n",
      "Comparing to: 'The dog is playing in the park'\n",
      "\n",
      "Similarity to 'The dog is playing in the park'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'A puppy is running outside'\n",
      "Score: 0.398\n",
      "\n",
      "Similarity to 'The cat is sleeping on the couch'\n",
      "Score: 0.071\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 0.099\n",
      "\n",
      "Similarity to 'Machine learning models need data'\n",
      "Score: -0.005\n",
      "\n",
      "Similarity to 'I love coding in Python'\n",
      "Score: 0.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function for cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "print(\"Similarity function ready!\")\n",
    "\n",
    "\n",
    "# Compare first sentence to all others\n",
    "print(\"Comparing to: 'The dog is playing in the park'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a211f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing to: 'TPython is a programming language'\n",
      "\n",
      "Similarity to 'The dog is playing in the park'\n",
      "Score: 0.099\n",
      "\n",
      "Similarity to 'A puppy is running outside'\n",
      "Score: 0.040\n",
      "\n",
      "Similarity to 'The cat is sleeping on the couch'\n",
      "Score: 0.020\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'Machine learning models need data'\n",
      "Score: 0.113\n",
      "\n",
      "Similarity to 'I love coding in Python'\n",
      "Score: 0.730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare fourth sentence to all others\n",
    "print(\"Comparing to: 'TPython is a programming language'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[3], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f635a2",
   "metadata": {},
   "source": [
    "## Exercise 2: Chunk size impact on Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73bffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document to work on\n",
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6379e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRetriever class ready!\n"
     ]
    }
   ],
   "source": [
    "class SimpleRetriever:\n",
    "  def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Initialize retriever with embedding model.\n",
    "    \"\"\"\n",
    "    self.model = SentenceTransformer(model_name)\n",
    "    self.chunks = []\n",
    "    self.embeddings = None\n",
    "\n",
    "  def add_documents(self, documents, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Add documents to the retriever (chunks and embeds them).\n",
    "    \"\"\"\n",
    "\n",
    "    # Simple chunking (from Module 2)\n",
    "    for doc in documents:\n",
    "      words = doc.split()\n",
    "      for i in range(0, len(words), chunk_size):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        self.chunks.append(chunk)\n",
    "\n",
    "    # Generate embeddings\n",
    "    print(f\"Embedding {len(self.chunks)} chunks ...\")\n",
    "    self.embeddings = self.model.encode(self.chunks)\n",
    "    print(f\"✅ Ready! {len(self.chunks)} chunks indexed\")\n",
    "\n",
    "  def search(self, query, top_k=3):\n",
    "    \"\"\"\n",
    "    Search for relevant chunks\n",
    "    \"\"\"\n",
    "    # Embed query\n",
    "    query_embedding = self.model.encode(query)\n",
    "\n",
    "    # Calculate Similarities\n",
    "    similarities = []\n",
    "    for i, chunk_emb in enumerate(self.embeddings):\n",
    "      sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "      similarities.append((self.chunks[i], sim))\n",
    "\n",
    "    # Sort and return top k\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "  \n",
    "print(\"SimpleRetriever class ready!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03842b",
   "metadata": {},
   "source": [
    "### Small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc7e49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1294 chunks ...\n",
      "✅ Ready! 1294 chunks indexed\n",
      "\n",
      "================================================================================\n",
      "Query: What is Machine learning\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 2 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 3 (Score: 0.140):\n",
      "k\n",
      "\n",
      "================================================================================\n",
      "Query: How can i classify Natural Language Processing\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.118):\n",
      "A\n",
      "\n",
      "Result 2 (Score: 0.118):\n",
      "a\n",
      "\n",
      "Result 3 (Score: 0.118):\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create retriever and add documents\n",
    "retriever = SimpleRetriever()\n",
    "retriever.add_documents(document, chunk_size=100)\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"What is Machine learning\",\n",
    "    \"How can i classify Natural Language Processing\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    results = retriever.search(query, top_k=3)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {score:.3f}):\")\n",
    "        print(chunk.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c8be262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document to work on\n",
    "document2 = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ad1e7",
   "metadata": {},
   "source": [
    "#### Medium chunks (200 Characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "291cf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1294 chunks ...\n",
      "✅ Ready! 1294 chunks indexed\n",
      "\n",
      "================================================================================\n",
      "Query: What is Machine learning\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 2 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 3 (Score: 0.140):\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create retriever and add documents\n",
    "retriever = SimpleRetriever()\n",
    "retriever.add_documents(document2, chunk_size=200)\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"What is Machine learning\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    results = retriever.search(query, top_k=3)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {score:.3f}):\")\n",
    "        print(chunk.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f5a6e",
   "metadata": {},
   "source": [
    "#### Large Characters (400 Characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b00b7ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1294 chunks ...\n",
      "✅ Ready! 1294 chunks indexed\n",
      "\n",
      "================================================================================\n",
      "Query: What is Machine learning\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 2 (Score: 0.140):\n",
      "k\n",
      "\n",
      "Result 3 (Score: 0.140):\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create retriever and add documents\n",
    "retriever = SimpleRetriever()\n",
    "retriever.add_documents(document, chunk_size=400)\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"What is Machine learning\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    results = retriever.search(query, top_k=3)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {score:.3f}):\")\n",
    "        print(chunk.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
