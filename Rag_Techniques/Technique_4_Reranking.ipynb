{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique 4: Reranking\n",
    "\n",
    "## The Problem\n",
    "Initial retrieval isn't perfect. The top-5 docs might not be in optimal order.\n",
    "\n",
    "**Why?** Embedding models optimize for speed, not perfect ranking.\n",
    "\n",
    "## The Solution\n",
    "**Cross-Encoder Reranking:**\n",
    "1. Retrieve top-K docs (e.g., 20)\n",
    "2. Use powerful cross-encoder to rerank\n",
    "3. Take top-N after reranking (e.g., 5)\n",
    "\n",
    "Slower but more accurate!\n",
    "\n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ How Reranking Works: Two-Stage Retrieval\n",
    "\n",
    "**Stage 1: Fast Retrieval (Bi-Encoder)**\n",
    "- Retrieve MORE documents (e.g., top-10 or top-20)\n",
    "- Uses fast vector similarity (embeddings computed separately)\n",
    "- Goal: Cast a wide net - don't miss relevant docs\n",
    "\n",
    "**Stage 2: Accurate Reranking (Cross-Encoder)**\n",
    "- Take those candidates from Stage 1\n",
    "- Use powerful cross-encoder to score each query-doc pair\n",
    "- Keep only the BEST N (e.g., top-5)\n",
    "- Goal: Optimize ranking for maximum relevance\n",
    "\n",
    "### Example: Before vs After Reranking\n",
    "\n",
    "**Before Reranking (Vector Similarity):**\n",
    "```\n",
    "Query: \"MSME financing options\"\n",
    "\n",
    "Top-5 by cosine similarity:\n",
    "1. [SMEDAN overview] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.82\n",
    "2. [Financing options] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.81  ‚Üê Should be #1!\n",
    "3. [Registration process] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.79\n",
    "4. [Tax benefits] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.77\n",
    "5. [Loan requirements] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  0.76  ‚Üê Should be #2!\n",
    "```\n",
    "\n",
    "**After Reranking (Cross-Encoder):**\n",
    "```\n",
    "Retrieved 10, reranked, kept top-5:\n",
    "\n",
    "1. [Financing options] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.94  ‚úÖ NOW #1!\n",
    "2. [Loan requirements] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  0.89  ‚úÖ NOW #2!\n",
    "3. [Development Bank info] ‚îÄ‚îÄ‚îÄ‚îÄ 0.85\n",
    "4. [SMEDAN financing] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.82\n",
    "5. [BOI programs] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.78\n",
    "```\n",
    "\n",
    "**Result:** Much better document ranking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\working_with_LLMs\\llmenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Imports done!\n"
     ]
    }
   ],
   "source": [
    "from utils_openai import setup_openai_api, create_embeddings, create_llm, load_msme_data, create_vectorstore, get_baseline_prompt, load_existing_vectorstore\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print('[OK] Imports done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Initialized embeddings: text-embedding-3-small\n",
      "[OK] Initialized LLM: gpt-4o-mini (temp=0)\n",
      "[OK] Loaded 14 documents from msme.csv\n",
      "[OK] Created vector store: msme_t7 (14 docs)\n",
      "[OK] Base retriever ready (k=10)!\n"
     ]
    }
   ],
   "source": [
    "api_key = setup_openai_api()\n",
    "embeddings = create_embeddings(api_key)\n",
    "llm = create_llm(api_key)\n",
    "docs, metas, ids = load_msme_data('msme.csv')\n",
    "vectorstore = create_vectorstore(docs, metas, ids, embeddings, 'msme_t7', './chroma_db_t7')\n",
    "base_retriever = vectorstore.as_retriever(search_kwargs={'k': 10})  # Retrieve MORE for reranking\n",
    "print('[OK] Base retriever ready (k=10)!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Initialized embeddings: text-embedding-3-small\n",
      "[OK] Initialized LLM: gpt-4o-mini (temp=0)\n",
      "[OK] Loaded existing vector store: msme_t7\n",
      "[OK] Base retriever ready (k=10)!\n"
     ]
    }
   ],
   "source": [
    "api_key = setup_openai_api()\n",
    "embeddings = create_embeddings(api_key)\n",
    "llm = create_llm(api_key)\n",
    "vectorstore = load_existing_vectorstore(embeddings, 'msme_t7', './chroma_db_t7')\n",
    "base_retriever = vectorstore.as_retriever(search_kwargs={'k': 10})  # Retrieve MORE for reranking\n",
    "print('[OK] Base retriever ready (k=10)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Cross-Encoder Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Bi-Encoder vs Cross-Encoder: The Key Difference\n",
    "\n",
    "### Bi-Encoder (Used in Vector Search - Stage 1)\n",
    "```\n",
    "Query ‚Üí Embed ‚Üí Vector_Q  ‚îÄ‚îê\n",
    "                            ‚îú‚Üí cosine_similarity(Vector_Q, Vector_D)\n",
    "Doc ‚Üí Embed ‚Üí Vector_D    ‚îÄ‚îò\n",
    "```\n",
    "- **Process:** Query and document embedded **separately**\n",
    "- **Comparison:** Simple cosine similarity between vectors\n",
    "- **Speed:** FAST\n",
    "- **Accuracy:** Good (but misses nuanced relevance)\n",
    "\n",
    "### Cross-Encoder (Used in Reranking - Stage 2)\n",
    "```\n",
    "[Query + Doc] ‚Üí Feed TOGETHER into model ‚Üí Relevance Score\n",
    "```\n",
    "- **Process:** Query and document processed **together** as a pair\n",
    "- **Comparison:** Model sees both at once, captures interaction\n",
    "- **Speed:** SLOWER (must run model for each query-doc pair)\n",
    "- **Accuracy:** EXCELLENT (captures semantic relationships)\n",
    "\n",
    "**Why Cross-Encoder is More Accurate:**\n",
    "- Sees query and doc together (not in isolation)\n",
    "- Can capture word interactions and context\n",
    "- Optimized specifically for ranking tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\working_with_LLMs\\llmenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reranker created!\n"
     ]
    }
   ],
   "source": [
    "# Using HuggingFace cross-encoder model:\n",
    "model = HuggingFaceCrossEncoder(model_name='cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "reranker = CrossEncoderReranker(model=model, top_n=5)  # Rerank and keep top 5\n",
    "print('[OK] Reranker created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Wrap with ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reranking retriever ready!\n"
     ]
    }
   ],
   "source": [
    "reranking_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "print('[OK] Reranking retriever ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reranking RAG chain ready!\n"
     ]
    }
   ],
   "source": [
    "prompt = get_baseline_prompt()\n",
    "\n",
    "reranking_rag_chain = (\n",
    "    {'context': reranking_retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print('[OK] Reranking RAG chain ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base retrieval: 10 docs\n",
      "After reranking: 5 docs\n",
      "\n",
      "Top doc after reranking:\n",
      "CHALLENGES CONFRONTING MSMEs IN NIGERIA The Micro, Small and Medium Enterprises (MSMEs) have been known, in both developed and developing nations, to be incontrovertible contributors to employment generation, wealth creation and poverty alleviation. It is on this premise that several efforts are gea\n",
      "\n",
      "Answer:\n",
      "Micro, Small, and Medium Enterprises (MSMEs) in Nigeria face several significant challenges that hinder their growth and sustainability. Key issues include limited access to financing due to high-interest rates and stringent collateral requirements, inadequate infrastructure such as unstable power supply and poor transportation networks, and complex regulatory frameworks that create bureaucratic hurdles (SMEDAN). Additionally, MSMEs struggle with market access and competition from larger firms, as well as a lack of skilled labor and technological adoption (World Bank). These challenges collectively impede the potential of MSMEs to contribute effectively to Nigeria's economy, despite their critical role in employment generation and GDP contribution.\n"
     ]
    }
   ],
   "source": [
    "question = 'What are the challenges faced by MSMEs in Nigeria?'\n",
    "\n",
    "# Compare base retrieval order vs reranked order\n",
    "base_docs = base_retriever.invoke(question)\n",
    "reranked_docs = reranking_retriever.invoke(question)\n",
    "\n",
    "print(f'Base retrieval: {len(base_docs)} docs')\n",
    "print(f'After reranking: {len(reranked_docs)} docs')\n",
    "print(f'\\nTop doc after reranking:')\n",
    "print(reranked_docs[0].page_content[:300])\n",
    "\n",
    "answer = reranking_rag_chain.invoke(question)\n",
    "print(f'\\nAnswer:\\n{answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Performance Trade-offs\n",
    "\n",
    "| Aspect | Vector Search Only | With Reranking |\n",
    "|--------|-------------------|----------------|\n",
    "| **Speed** | Very fast (~10ms) | Slower (~100-500ms) |\n",
    "| **Accuracy** | Good (70-80%) | Excellent (85-95%) |\n",
    "| **Cost** | Cheap | More expensive |\n",
    "| **Computation** | Pre-computed embeddings | Must score each pair |\n",
    "| **Use Case** | Speed-critical apps | Quality-critical tasks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use\n",
    "**Use when:**\n",
    "- Accuracy critical\n",
    "- Initial retrieval misses best docs\n",
    "- Can afford extra computation\n",
    "\n",
    "**Avoid when:**\n",
    "- Speed is priority\n",
    "- Initial retrieval already good\n",
    "- Extra cost unjustified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Compare answers with/without reranking\n",
    "2. Test different reranker models\n",
    "3. Measure quality improvement\n",
    "\n",
    "Time: 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** Technique 5 - HyDE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
