{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c1fe00",
   "metadata": {},
   "source": [
    "## Chunking Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c4801",
   "metadata": {},
   "source": [
    "### Setup Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432d6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document length: 1367 characters\n",
      "Document length: 187 words\n",
      "\n",
      "First 200 characters:\n",
      "\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. \n",
      "It was created by Guido van Rossum and first released in 1991. Python supports multiple programming...\n"
     ]
    }
   ],
   "source": [
    "# Sample document about Python programming\n",
    "sample_document = \"\"\"\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability. \n",
    "It was created by Guido van Rossum and first released in 1991. Python supports multiple programming \n",
    "paradigms including procedural, object-oriented, and functional programming.\n",
    " \n",
    "One of Python's key strengths is its extensive standard library, which provides tools for many common \n",
    "programming tasks. The language emphasizes code readability with its use of significant indentation. \n",
    "Python's syntax allows programmers to express concepts in fewer lines of code compared to languages \n",
    "like C++ or Java.\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, scientific computing, \n",
    "and automation. Popular frameworks include Django and Flask for web development, NumPy and Pandas for \n",
    "data analysis, and TensorFlow and PyTorch for machine learning.\n",
    "\n",
    "The Python Package Index (PyPI) hosts hundreds of thousands of third-party packages that extend Python's \n",
    "capabilities. Installation is simple using pip, Python's package installer. The active community contributes \n",
    "to a rich ecosystem of libraries and frameworks.\n",
    "\n",
    "Python continues to be one of the most popular programming languages worldwide. Its beginner-friendly nature \n",
    "makes it ideal for education, while its powerful features support professional software development and research.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Document length: {len(sample_document)} characters\")\n",
    "print(f\"Document length: {len(sample_document.split())} words\")\n",
    "print(f\"\\nFirst 200 characters:\\n{sample_document[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e7092",
   "metadata": {},
   "source": [
    "## Fixed chunking size(Character-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ed517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 10\n",
      "\n",
      "Chunk 1 (200 chars):\n",
      "\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. \n",
      "It was created by Guido van Rossum and first released in 1991. Python supports multiple programming\n",
      "================================================================================\n",
      "Chunk 2 (200 chars):\n",
      "ased in 1991. Python supports multiple programming \n",
      "paradigms including procedural, object-oriented, and functional programming.\n",
      "\n",
      "One of Python's key strengths is its extensive standard library, which\n",
      "================================================================================\n",
      "Chunk 3 (200 chars):\n",
      "strengths is its extensive standard library, which provides tools for many common \n",
      "programming tasks. The language emphasizes code readability with its use of significant indentation. \n",
      "Python's syntax\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_characters(text, chunk_size=200, overlap=50):\n",
    "  \"\"\"\n",
    "  Split text into chunks of specified character length\n",
    "\n",
    "  Args:\n",
    "        text: The text to chunk\n",
    "        chunk_size: Number of characters per chunk\n",
    "        overlap: Number of characters to overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "  \"\"\"\n",
    "  chunks =[]\n",
    "  start = 0\n",
    "\n",
    "  while start < len(text):\n",
    "    # Get chunk from start to + chunk size\n",
    "    end = start + chunk_size\n",
    "    chunk = text[start:end]\n",
    "    chunks.append(chunk)\n",
    "\n",
    "    # Move start position\n",
    "    start += chunk_size - overlap\n",
    "\n",
    "  return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_characters(sample_document, chunk_size=200, overlap=50)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks[:3], 1):   #Show first 3 chunks\n",
    "  print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "  print(chunk)\n",
    "  print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282644b",
   "metadata": {},
   "source": [
    "## Fixed-Size Chunking (Word-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58ae284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n",
      "\n",
      "Chunk 1 (50 words):\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. It was created by Guido van Rossum and first released in 1991. Python supports multiple programming paradigms including procedural, object-oriented, and functional programming. One of Python's key strengths is its extensive standard library, which provides tools for\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 2 (50 words):\n",
      "strengths is its extensive standard library, which provides tools for many common programming tasks. The language emphasizes code readability with its use of significant indentation. Python's syntax allows programmers to express concepts in fewer lines of code compared to languages like C++ or Java. Python is widely used in web\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 3 (50 words):\n",
      "like C++ or Java. Python is widely used in web development, data science, artificial intelligence, scientific computing, and automation. Popular frameworks include Django and Flask for web development, NumPy and Pandas for data analysis, and TensorFlow and PyTorch for machine learning. The Python Package Index (PyPI) hosts hundreds of thousands\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_words(text, chunk_size=50, overlap=10):\n",
    "  \"\"\"\n",
    "  Split text into chunks of specified word count.\n",
    "    \n",
    "  Args:\n",
    "      text: The text to chunk\n",
    "      chunk_size: Number of words per chunk\n",
    "      overlap: Number of words to overlap between chunks\n",
    "    \n",
    "  Returns:\n",
    "      List of text chunks\n",
    "    \"\"\"\n",
    "  # Split text into words\n",
    "  words = text.split()\n",
    "  chunks = []\n",
    "  start = 0\n",
    "\n",
    "  while start < len(words):\n",
    "    # Get chunk of words\n",
    "    end = start + chunk_size\n",
    "    chunk_words = words[start:end]\n",
    "\n",
    "    # Join words back into text\n",
    "    chunk = ' '.join(chunk_words)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "    # Move start position  (with overlap)\n",
    "    start += chunk_size - overlap\n",
    "  \n",
    "  return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_words(sample_document, chunk_size=50, overlap=10)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks[:3], 1):  # Show first 3 chunks\n",
    "    print(f\"Chunk {i} ({len(chunk.split())} words):\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5883381",
   "metadata": {},
   "source": [
    "## Sentence-Based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51d7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "\n",
      "Chunk 1 (398 chars):\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. It was created by Guido van Rossum and first released in 1991. Python supports multiple programming \n",
      "paradigms including procedural, object-oriented, and functional programming. One of Python's key strengths is its extensive standard library, which provides tools for many common \n",
      "programming tasks.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 2 (320 chars):\n",
      "The language emphasizes code readability with its use of significant indentation. Python's syntax allows programmers to express concepts in fewer lines of code compared to languages \n",
      "like C++ or Java. Python is widely used in web development, data science, artificial intelligence, scientific computing, \n",
      "and automation.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 3 (332 chars):\n",
      "Popular frameworks include Django and Flask for web development, NumPy and Pandas for \n",
      "data analysis, and TensorFlow and PyTorch for machine learning. The Python Package Index (PyPI) hosts hundreds of thousands of third-party packages that extend Python's \n",
      "capabilities. Installation is simple using pip, Python's package installer.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 4 (306 chars):\n",
      "The active community contributes \n",
      "to a rich ecosystem of libraries and frameworks. Python continues to be one of the most popular programming languages worldwide. Its beginner-friendly nature \n",
      "makes it ideal for education, while its powerful features support professional software development and research.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_sentences(text, max_chunk_size=500):\n",
    "  \"\"\"\n",
    "    Split text into chunks by sentences, keeping sentences intact.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "  # Simple sentence splitting (Split on . ! ?)\n",
    "  import re\n",
    "  sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "  chunks = []\n",
    "  current_chunk = \"\"\n",
    "\n",
    "  for sentence in sentences:\n",
    "    # Check if adding this sentence would exceed max size\n",
    "    if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:\n",
    "      # Save current chunk and start new one\n",
    "      chunks.append(current_chunk.strip())\n",
    "      current_chunk = sentence\n",
    "    else:\n",
    "      # Add sentence to current chunk\n",
    "      current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "\n",
    "  # Don't forget the last chunk\n",
    "  if current_chunk:\n",
    "    chunks.append(current_chunk.strip())\n",
    "  \n",
    "  return chunks\n",
    "\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_sentences(sample_document, max_chunk_size=400)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "  print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "  print(chunk)\n",
    "  print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d350047",
   "metadata": {},
   "source": [
    "## Paragraph-Based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f6735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_paragraphs(text, min_chunk_size= 100):\n",
    "  \"\"\"\n",
    "  Split text by paragraphs (double newlines).\n",
    "    \n",
    "  Args:\n",
    "      text: The text to chunk\n",
    "      min_chunk_size: Minimum characters per chunk (combine small paragraphs)\n",
    "    \n",
    "  Returns:\n",
    "      List of text chunks\n",
    "  \"\"\"\n",
    "  # Split by double newlines (paragraph seperator)\n",
    "  paragraphs = text.split('\\n\\n')\n",
    "\n",
    "  chunks = []\n",
    "  current_chunk = \"\"\n",
    "  \n",
    "  for para in paragraphs:\n",
    "    para = para.strip()\n",
    "    if not para:\n",
    "      continue\n",
    "\n",
    "    # If paragraph is too small, combine with next\n",
    "    if len(para) < min_chunk_size:\n",
    "      current_chunk += \"\\n\\n\" + para if current_chunk else para\n",
    "    else:\n",
    "      # Save previous chunk if exists\n",
    "      if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "  return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_paragraphs(sample_document, min_chunk_size=100)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "  print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "  print(chunk)\n",
    "  print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95d53d",
   "metadata": {},
   "source": [
    "### Adding Metadata to chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d2a49",
   "metadata": {},
   "source": [
    "#### Implementing Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcf2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_with_metadata(text, source_name, chunk_size=50, overlap=10):\n",
    "  \"\"\"\n",
    "  Create chunks with metadata.\n",
    "    \n",
    "  Args:\n",
    "      text: The text to chunk\n",
    "      source_name: Name of the source document\n",
    "      chunk_size: Number of words per chunk\n",
    "      overlap: Number of words to overlap\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with 'text' and 'metadata'\n",
    "    \"\"\"\n",
    "  # Get basic chunks\n",
    "  words = text.split()\n",
    "  chunks = []\n",
    "  start = 0\n",
    "  chunk_index = 0\n",
    "\n",
    "  while start < len(words):\n",
    "    end = start + chunk_size\n",
    "    chunk_words = words[start:end]\n",
    "    chunk_text = ' '.join(chunk_words)\n",
    "\n",
    "    # Create chunk with metadata\n",
    "    chunk_with_meta = {\n",
    "      'text': chunk_text,\n",
    "      'metadata': {\n",
    "        'source': source_name,\n",
    "        'chunk_index': chunk_index,\n",
    "        'chunk_size': len(chunk_words),\n",
    "        'char_count': len(chunk_text),\n",
    "        'start_word': start,\n",
    "        'end_word': end\n",
    "      }\n",
    "    }\n",
    "\n",
    "    chunks.append(chunk_with_meta)\n",
    "    start += chunk_size - overlap\n",
    "    chunk_index += 1\n",
    "  return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk+chunk_with_metadata(\n",
    "  sample_document,\n",
    "  source_name=\"example.txt\",\n",
    "  chunk_size=5,\n",
    "  overlap=10\n",
    ")\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\\n\")\n",
    "print(\"First chunk with metadata:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Text: {chunks[1]['text'][:200]}...\")\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in chunks[1]['metadata'].items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1a907",
   "metadata": {},
   "source": [
    "## Loading and Chunking Real Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccd2a3",
   "metadata": {},
   "source": [
    "### Loading Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1eb9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_chunk_text_file(file_path, chunk_size=500, overlap=50):\n",
    "    \"\"\"\n",
    "    Load a text file and chunk it.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the text file\n",
    "        chunk_size: Characters per chunk\n",
    "        overlap: Character overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of chunks with metadata\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Get file metadata\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    \n",
    "    # Chunk the text\n",
    "    chunks = chunk_by_sentences(text, max_chunk_size=chunk_size)\n",
    "    \n",
    "    # Add metadata to each chunk\n",
    "    chunks_with_metadata = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunks_with_metadata.append({\n",
    "            'text': chunk,\n",
    "            'metadata': {\n",
    "                'source': file_name,\n",
    "                'file_path': file_path,\n",
    "                'file_size': file_size,\n",
    "                'chunk_index': i,\n",
    "                'total_chunks': len(chunks)\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return chunks_with_metadata\n",
    "\n",
    "# Example usage (create a sample file first)\n",
    "sample_file_path = 'sample_document.txt'\n",
    "with open(sample_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_document)\n",
    "\n",
    "# Load and chunk\n",
    "chunks = load_and_chunk_text_file(sample_file_path, chunk_size=400)\n",
    "\n",
    "print(f\"Loaded and chunked: {chunks[0]['metadata']['source']}\")\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(f\"\\nChunk 1:\")\n",
    "print(chunks[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[2]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e08415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_chunk_pdf(file_path, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Load a PDF file and chunk it.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the PDF file\n",
    "        chunk_size: Characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of chunks with metadata (including page numbers)\n",
    "    \"\"\"\n",
    "    import PyPDF2\n",
    "    import os\n",
    "    \n",
    "    chunks_with_metadata = []\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Open PDF\n",
    "    with open(file_path, 'rb') as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        # Process each page\n",
    "        for page_num in range(num_pages):\n",
    "            # Extract text from page\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            \n",
    "            # Chunk the page text\n",
    "            page_chunks = chunk_by_sentences(text, max_chunk_size=chunk_size)\n",
    "            \n",
    "            # Add metadata to each chunk\n",
    "            for chunk_idx, chunk in enumerate(page_chunks):\n",
    "                chunks_with_metadata.append({\n",
    "                    'text': chunk,\n",
    "                    'metadata': {\n",
    "                        'source': file_name,\n",
    "                        'page': page_num + 1,  # 1-indexed\n",
    "                        'total_pages': num_pages,\n",
    "                        'chunk_on_page': chunk_idx,\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    return chunks_with_metadata\n",
    "\n",
    "# Example (you would use this with a real PDF file)\n",
    "print(\"PDF loading function ready!\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"chunks = load_and_chunk_pdf('your_document.pdf', chunk_size=500)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can test the load_and_chunk function with the code below\n",
    "\n",
    "# chunks = load_and_chunk_pdf(\"Retrieval-Augmented_Generation_RAG.pdf\", chunk_size=500)\n",
    "\n",
    "# print(f\"Total chunks: {len(chunks)}\\n\")\n",
    "\n",
    "# for i, c in enumerate(chunks[:5]):  # show first 5 chunks\n",
    "#     print(f\"CHUNK {i+1}\")\n",
    "#     print(\"TEXT:\", c[\"text\"][:200])  # print first 200 chars\n",
    "#     print(\"META:\", c[\"metadata\"])\n",
    "#     print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546d25d",
   "metadata": {},
   "source": [
    "## Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd67f9",
   "metadata": {},
   "source": [
    "#### Document A: FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa630f9a",
   "metadata": {},
   "source": [
    "Strategy_A\n",
    "Sentence chunking \n",
    "\n",
    "\n",
    "Reason_A\n",
    "Sentence chunking becuse the FAQ documents questions are in a single sentence so it will be easy to retrieve answer for each sentence \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a = \"\"\"\n",
    "Q: What is the return policy?\n",
    "A: Items can be returned within 30 days of purchase with original receipt.\n",
    "\n",
    "Q: Do you offer international shipping?\n",
    "A: Yes, we ship to over 50 countries worldwide. Shipping times vary by location.\n",
    "\n",
    "Q: How do I track my order?\n",
    "A: Use the tracking number sent to your email after shipment.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae901393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7\n",
      "\n",
      "Chunk 1 (29 chars):\n",
      "Q: What is the return policy?\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 2 (74 chars):\n",
      "A: Items can be returned within 30 days of purchase with original receipt.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 3 (39 chars):\n",
      "Q: Do you offer international shipping?\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 4 (47 chars):\n",
      "A: Yes, we ship to over 50 countries worldwide.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 5 (32 chars):\n",
      "Shipping times vary by location.\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 6 (27 chars):\n",
      "Q: How do I track my order?\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk 7 (61 chars):\n",
      "A: Use the tracking number sent to your email after shipment.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_sentences(text, max_chunk_size=50):\n",
    "  \"\"\"\n",
    "    Split text into chunks by sentences, keeping sentences intact.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "  # Simple sentence splitting (Split on . ! ?)\n",
    "  import re\n",
    "  sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "  chunks = []\n",
    "  current_chunk = \"\"\n",
    "\n",
    "  for sentence in sentences:\n",
    "    # Check if adding this sentence would exceed max size\n",
    "    if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:\n",
    "      # Save current chunk and start new one\n",
    "      chunks.append(current_chunk.strip())\n",
    "      current_chunk = sentence\n",
    "    else:\n",
    "      # Add sentence to current chunk\n",
    "      current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "\n",
    "  # Don't forget the last chunk\n",
    "  if current_chunk:\n",
    "    chunks.append(current_chunk.strip())\n",
    "  \n",
    "  return chunks\n",
    "\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_sentences(doc_a, max_chunk_size=50)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "  print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "  print(chunk)\n",
    "  print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d56012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_b = \"\"\"\n",
    "Installation Guide\n",
    "\n",
    "Step 1: Download the installer from our website.\n",
    "Extract the zip file to your desired location.\n",
    "\n",
    "Step 2: Run setup.exe as administrator.\n",
    "Follow the on-screen instructions.\n",
    "\n",
    "Step 3: Configure your API key in the settings file.\n",
    "The settings file is located at config/settings.json.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6f4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_c = \"\"\"\n",
    "The Future of Renewable Energy\n",
    "\n",
    "Solar and wind power have seen tremendous growth in recent years. As technology improves\n",
    "and costs decrease, renewable energy becomes increasingly competitive with fossil fuels.\n",
    "\n",
    "Energy storage solutions are critical for renewable adoption. Battery technology advances\n",
    "enable better grid management and reliability. This addresses the intermittent nature of\n",
    "solar and wind power.\n",
    "\n",
    "Policy support and public awareness continue to drive the transition. Many countries have\n",
    "set ambitious renewable energy targets for the coming decades.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478f1b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
